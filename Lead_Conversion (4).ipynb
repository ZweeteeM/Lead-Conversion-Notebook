  {
   "cell_type": "markdown",
   "metadata": {
    "id": "584Ks_SDHOBt"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Project Overview](#chapter1)\n",
    "  * [1.1 Introduction](#section_1_1)\n",
    "      * [1.1.1 Problem Statement](#sub_section_1_1_1)\n",
    "      * [1.1.2 Objectives](#sub_section_1_1_2)\n",
    "* [2. Importing Packages](#chapter2)\n",
    "* [3. Loading Data](#chapter3)\n",
    "* [4. Data Cleaning](#chapter4)\n",
    "* [5. Exploratory Data Analysis (EDA)](#chapter5)\n",
    "* [6. Model training](#chapter7)\n",
    "* [7. Model Performance Comparison and evaluation](#chapter8)\n",
    "* [8. Fine-tune model parameters and hyperparameters](#chapter9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmjiILSaHOBv"
   },
   "source": [
    "# <font color=black>1. Project Overview</font> <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws2cryo0HOBv"
   },
   "source": [
    "This project aims to build a predictive machine learning model to assess the likelihood of customer lead conversion.\n",
    "Leveraging a dataset with various lead attributes, the project will apply comprehensive data cleaning,\n",
    "feature engineering, and machine learning techniques to identify the key factors that influence lead outcomes.\n",
    "In addition to model development, the project will conduct exploratory data analysis (EDA)\n",
    "to extract actionable insights from the data, which will be visualized through an interactive dashboard.\n",
    "These insights are designed to help businesses optimize their marketing strategies and\n",
    "improve overall lead conversion rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbT9m9DAHOBw"
   },
   "source": [
    "## 1.1.1 Problem Statement <a class=\"anchor\" id=\"sub_section_1_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRn29yfBHOBw"
   },
   "source": [
    "Many businesses face the challenge of low lead conversion rates, which hampers the efficiency of their marketing efforts and results in wasted resources. Without a clear understanding of which leads are most likely to convert, companies often spend time and budget pursuing low-potential leads, leading to missed revenue opportunities. This project seeks to address this issue by developing a machine learning model that predicts the likelihood of lead conversion based on historical data. By identifying key factors that influence conversion, businesses can make data-driven decisions to optimize their marketing strategies, prioritize high-potential leads, and ultimately improve conversion rates while reducing costs.sed revenue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PKY_GlFHOBx"
   },
   "source": [
    "## 1.1.2 Objectives <a class=\"anchor\" id=\"sub_section_1_1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO97_A6wHOBx"
   },
   "source": [
    "1. **Predict Lead Conversion Probability**  \n",
    "   Develop a machine learning model to accurately predict the likelihood of customer lead conversion, enabling businesses to focus on high-potential leads.\n",
    "\n",
    "2. **Optimize Marketing Strategies**  \n",
    "   Provide actionable insights that help businesses refine and enhance their marketing strategies based on lead conversion predictions.\n",
    "\n",
    "3. **Improve Resource Allocation**  \n",
    "   Facilitate more efficient resource allocation by prioritizing leads with higher conversion potential, ultimately reducing costs associated with unconverted leads.\n",
    "\n",
    "4. **Increase Revenue**  \n",
    "   Support businesses in making data-driven decisions that can lead to improved lead conversion rates, contributing to increased revenue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUCtoJyqHOBy"
   },
   "source": [
    "# <font color=black>2. Importing Packages</font> <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6lTQImcHOBy",
    "outputId": "70f207ce-6e0f-4645-f96a-9c69d593a780"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLi83BjbHOB1"
   },
   "source": [
    "# <font color=black> 3. Loading Data</font> <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Leads_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4npYG5T7HOB1"
   },
   "source": [
    "## Dataset Overview\n",
    "\n",
    "The dataset contains customer lead information aimed at predicting lead conversion rates, with features spanning demographic, behavioral, and transactional data. Key attributes include:\n",
    "\n",
    "- **LeadOutcome:** Final outcome of the lead (e.g., converted, not converted).\n",
    "- **IsMarketingAllowed:** Permission for marketing communication.\n",
    "- **Title:** Lead's title (e.g., Mr., Mrs., Dr.).\n",
    "- **PostalProvince:** Lead's geographic location.\n",
    "- **IdentificationType:** Type of ID provided (e.g., national ID).\n",
    "- **Gender, Age, MaritalStatus:** Demographic details.\n",
    "- **Vehicle Details:** Includes Annual Mileage, Licence Duration, Make, Model, and Previous Insurer.\n",
    "- **Lead Age, MediaChannel, LeadSource:** Lead acquisition details.\n",
    "- **Call Interaction Metrics:** Metrics such as total and answered calls, contact success rates.\n",
    "\n",
    "We will load the dataset, inspect the first few rows, and display data information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvrmJ8KiHOB2"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjExOrAWHOB2"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8jXAzjYHOB2"
   },
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qGUq_bNHOB3"
   },
   "source": [
    "# <font color=black> 4. Data cleaning</font> <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIkjb_x3HOB3"
   },
   "source": [
    "Data cleaning is the process of fixing bad data in our dataset. This step is crucial in the data analysis process, it helps ensure that the data is accurate, consistent, and reliable. Clean data leads to more accurate analysis and modeling results, thus provides a solid foundation for decision-making. The dataset might contain missing values in key columns, particularly related to vehicle and previous insurance details,\n",
    "which will be addressed during data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vk-9u1zYHOB3"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OS-5iWPXHOB3",
    "outputId": "3b8656f8-52bc-4b7a-8aeb-5ce03fc7a665"
   },
   "outputs": [],
   "source": [
    "\n",
    "df['AnnualMileage'] = df['AnnualMileage'].replace({'<5000 km': '5000', '5000-10000 km': '7500', '>20000 km': '20000'})\n",
    "\n",
    "# Convert the column to numeric\n",
    "df['AnnualMileage'] = pd.to_numeric(df['AnnualMileage'], errors='coerce')\n",
    "\n",
    "# Now, fill missing values with median\n",
    "df['AnnualMileage'].fillna(df['AnnualMileage'].median(), inplace=True)\n",
    "\n",
    "df['NewPriceVatExcl'] = df['NewPriceVatExcl'].replace({'<5000': '5000', '>10000': '10000'})\n",
    "df['NewPriceVatExcl'] = pd.to_numeric(df['NewPriceVatExcl'], errors='coerce')\n",
    "df['NewPriceVatExcl'].fillna(df['NewPriceVatExcl'].median(), inplace=True)\n",
    "\n",
    "# Similarly, handle 'RetailPriceVatExcl'\n",
    "df['RetailPriceVatExcl'] = df['RetailPriceVatExcl'].replace({'<5000': '5000', '>10000': '10000'})\n",
    "df['RetailPriceVatExcl'] = pd.to_numeric(df['RetailPriceVatExcl'], errors='coerce')\n",
    "df['RetailPriceVatExcl'].fillna(df['RetailPriceVatExcl'].median(), inplace=True)\n",
    "\n",
    "# Final null check\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psjZSuJlHOB4",
    "outputId": "d5c39ed5-3f1b-4635-8084-a5ecd694a6f4"
   },
   "outputs": [],
   "source": [
    "# Fill missing values in numerical columns with the median\n",
    "df['LicenceDurationRange'].fillna(df['LicenceDurationRange'].mode()[0], inplace=True)\n",
    "df['TradePriceVatExcl'].fillna(df['TradePriceVatExcl'].median(), inplace=True)\n",
    "df['QuotedExcess'].fillna(df['QuotedExcess'].median(), inplace=True)\n",
    "df['TotalQuotedPremium'].fillna(df['TotalQuotedPremium'].median(), inplace=True)\n",
    "\n",
    "# Handle PreviousInsurerPremium with 0 if missing represents no premium\n",
    "df['PreviousInsurerPremium'].fillna(0, inplace=True)\n",
    "\n",
    "# For LeadCreateDt, use forward fill to propagate the last valid value forward\n",
    "df['LeadCreateDt'] = pd.to_datetime(df['LeadCreateDt'], errors='coerce')  # Ensure the column is datetime\n",
    "df['LeadCreateDt'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Final check for remaining nulls\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAMejyBPHOB4",
    "outputId": "888989bc-62ec-4fe1-d5cf-fb01c49b10d2"
   },
   "outputs": [],
   "source": [
    "# Fill categorical columns with mode or 'Unknown'\n",
    "df['Title'].fillna('Unknown', inplace=True)\n",
    "df['PostalProvince'].fillna(df['PostalProvince'].mode()[0], inplace=True)\n",
    "df['IdentificationType'].fillna('Unknown', inplace=True)\n",
    "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n",
    "df['MaritalStatus'].fillna(df['MaritalStatus'].mode()[0], inplace=True)\n",
    "df['Make'].fillna('Unknown', inplace=True)\n",
    "df['Model'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Fill numerical columns with median\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['TradePriceVatExcl'].fillna(df['TradePriceVatExcl'].median(), inplace=True)\n",
    "\n",
    "# Large amount of missing data, fill with 'Unknown'\n",
    "df['PreviousInsurer'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Check for remaining missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmHZnvpmIX8u"
   },
   "source": [
    "#Duplicates\n",
    "\n",
    "The dataset contained significant duplicates, indicating potential redundancy. After identifying the duplicates, the approach was to remove them to ensure a cleaner analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XbvT6HaHOB5",
    "outputId": "4bbaee80-48d5-4641-b972-178e2875dd50"
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "print(\"Number of duplicate rows:\", duplicates.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Spigrz1LHOB5"
   },
   "source": [
    "### Map LeadOutcome to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TxZsytbHOB5"
   },
   "outputs": [],
   "source": [
    "df['LeadOutcome'] = df['LeadOutcome'].map({\n",
    "    'SaleConcluded': 1,  # Lead was converted\n",
    "    'Filed': 0  # Lead was not converted\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9pi5q-kHOB6"
   },
   "source": [
    "### Drop rows with missing LeadOutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-awuhT4HOB6"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['LeadOutcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nfcp-qFBHOB6"
   },
   "source": [
    "# <font color=black>5. Exploratory Data Analysis</font> <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ2o8kzkHOB6"
   },
   "source": [
    "Exploratory Data Analysis (EDA) is a crucial step in any data science project, providing a foundation for understanding the dataset.\n",
    "It helps uncover patterns, identify anomalies, and test hypotheses. In this project, we\n",
    "conduct EDA on a dataset consisting of news articles, which include various attributes such as headlines,\n",
    "descriptions, full content, URLs, and categories.\n",
    "\n",
    "The primary objective of this EDA is to gain insights into the structure and characteristics of the data.\n",
    "This analysis will help identify potential issues or data quality problems that need to be\n",
    "addressed before moving on to the subsequent modeling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1e2EfOnHOB7",
    "outputId": "0bd30552-805b-44ee-cbb6-160f5a8e2dcb"
   },
   "outputs": [],
   "source": [
    "# Visualize distribution of LeadOutcome\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='LeadOutcome', data=df)\n",
    "plt.title('Distribution of LeadOutcome')\n",
    "plt.show()\n",
    "\n",
    "# Percentage of each class in LeadOutcome\n",
    "print(df['LeadOutcome'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdZqH1vIJXBj"
   },
   "source": [
    "Insights:\n",
    "\n",
    "This indicates an imbalance in the LeadOutcome distribution, with '1's (representing successful lead outcomes) making up the majority of the data, around 90% (from the percentage calculation), while '0's (unsuccessful lead outcomes) account for about 10%.\n",
    "\n",
    "The high number of positive outcome suggests that a large proportion of leads in the dataset convert successfully. However, the imbalance can impact model performance, as machine learning models may become biased towards predicting '1' more often, given the higher frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u04m5uG-HOB7"
   },
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGrV599GJfmx"
   },
   "source": [
    "The selected features for this analysis include a combination of demographic, vehicle, and lead-related attributes that are expected to influence lead conversion. Key demographic features like Title, Gender, Age, and MaritalStatus provide insights into the customer profile, while vehicle-related features such as AnnualMileage, Make, Model, NewPriceVatExcl, and RetailPriceVatExcl give details about the car being considered. Additionally, features like PreviousInsurer and PreviousInsurerPremium shed light on the customer's past insurance experience.\n",
    "\n",
    "Lead-specific features like Lead Age (Calendar Days), TotalCalls, SuccessfulContacts, UnsuccessfulContacts, and HasBeenReworked? help in understanding the lead engagement process, while MediaChannel and LeadSource offer insights into how the lead was generated. These features collectively provide a comprehensive view of factors that could influence lead conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrtBcRTMHOB8"
   },
   "outputs": [],
   "source": [
    "features_to_include = [\n",
    "    'Title', 'Gender', 'Age', 'MaritalStatus',\n",
    "    'AnnualMileage', 'LicenceDurationRange',\n",
    "    'Make', 'Model', 'NewPriceVatExcl',\n",
    "    'RetailPriceVatExcl', 'TradePriceVatExcl',\n",
    "    'PreviousInsurer', 'PreviousInsurerPremium',\n",
    "    'Lead Age (Calendar Days)', 'MediaChannel',\n",
    "    'LeadSource', 'TotalCalls', 'SuccessfulContacts',\n",
    "    'UnsuccessfulContacts', 'HasBeenReworked?'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5Jrsb4hHOB8"
   },
   "source": [
    "### Create feature set (X) and target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZ9EEjPfHOB9"
   },
   "outputs": [],
   "source": [
    "X = df[features_to_include]\n",
    "y = df['LeadOutcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPNbJayLHOB9"
   },
   "source": [
    "### Handle categorical variables (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsDAb0VtHOB9"
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqvaT2FQHOB9"
   },
   "source": [
    "### Distribution of Target Variable (LeadOutcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwTVIlvbHOB-",
    "outputId": "2d9f8813-5173-4281-f5cb-2266ae9c9ac9"
   },
   "outputs": [],
   "source": [
    "# Visualize distribution of LeadOutcome\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='LeadOutcome', data=df)\n",
    "plt.title('Distribution of LeadOutcome')\n",
    "plt.show()\n",
    "\n",
    "# Percentage of each class in LeadOutcome\n",
    "print(df['LeadOutcome'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iL4ZZ0rEKDpP"
   },
   "source": [
    "Insights:\n",
    "\n",
    "This indicates an imbalance in the LeadOutcome distribution, with '1's (representing successful lead outcomes) making up the majority of the data, around 90%, while '0's (unsuccessful lead outcomes) account for about 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7clbN6PHOB-"
   },
   "source": [
    "### Corelation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cl1vZuoOHOB_",
    "outputId": "72f2da70-b0d6-4ac6-f66a-9b9f94742af9"
   },
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ki-99r_tMjd-"
   },
   "source": [
    "Insights:\n",
    "\n",
    "Metrics related to call frequency and lead age are crucial factors that could influence the lead outcome. On the other hand, factors like the individual's age and marketing permissions have minimal impact on outcomes. This could guide focus areas for improving lead conversions, such as optimizing call strategies or prioritizing fresher leads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhlTjo6bHOB_"
   },
   "source": [
    "### Numerical Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5m9dXJeAHOCA",
    "outputId": "c55eae7c-3848-4380-d55e-0bd05b7e4016"
   },
   "outputs": [],
   "source": [
    "# Plot distribution of numerical features\n",
    "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Adjust the number of rows based on the number of features\n",
    "n_features = len(numerical_features)\n",
    "n_cols = 3\n",
    "n_rows = (n_features // n_cols) + (n_features % n_cols > 0)  # Calculate rows needed\n",
    "\n",
    "plt.figure(figsize=(16, 4 * n_rows))  # Adjust figure height based on rows\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.histplot(df[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99Kq6N8_NrY2"
   },
   "source": [
    "Insights:\n",
    "\n",
    "- Skewed Distributions: Most numerical variables, especially those related to pricing, calls, and vehicle metrics, are right-skewed.\n",
    "\n",
    "- Lead Segmentation: Variables such as age, lead age, and call attempts could help segment leads into different engagement groups, potentially improving conversion strategies.\n",
    "\n",
    "- Premium Calculations: Factors like AnnualMileage, VehicleYear, and MileageAtInception may play roles in calculating premiums, especially given their varied distributions, which show high diversity in customer profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYsWgUFqHOCA"
   },
   "source": [
    "### Categorical Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEeAcE04HOCA",
    "outputId": "6031812e-8e5e-43de-c388-6373f536ea45"
   },
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Adjust the number of rows based on the number of features\n",
    "n_features = len(categorical_columns)\n",
    "n_cols = 3\n",
    "n_rows = (n_features // n_cols) + (n_features % n_cols > 0)  # Calculate rows needed\n",
    "\n",
    "plt.figure(figsize=(10, 4 * n_rows))  # Adjust figure height based on rows\n",
    "for i, feature in enumerate(categorical_columns, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.histplot(df[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjXwCgjsQFzG"
   },
   "source": [
    "Insights:\n",
    "\n",
    "- Market Segmentation: The skew in certain fields (e.g., PostalProvince, VehicleMake, MediaChannel) could be used for market segmentation, allowing for more targeted advertising.\n",
    "- Risk and Premium Assessment: Variables like License Duration Range, VehicleModel, and Driver's License Code may help assess risk profiles, which could influence pricing and underwriting policies.\n",
    "- Product Customization: Understanding demographic variables like MaritalStatus and Title can assist in tailoring products or offers to suit specific customer needs.\n",
    "- Channel Effectiveness: MediaChannel and LeadSource distributions highlight the most successful lead generation methods, providing insights into effective marketing channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWB1OsMRHOCB"
   },
   "source": [
    "###  Feature Relationships with LeadOutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_FzeL24HOCB",
    "outputId": "986418bd-fad1-4b57-f1da-0bd855f538de"
   },
   "outputs": [],
   "source": [
    "# Adjust the number of rows based on the number of numerical features\n",
    "n_features = len(numerical_features)\n",
    "n_cols = 3\n",
    "n_rows = (n_features // n_cols) + (n_features % n_cols > 0)  # Calculate the required number of rows\n",
    "\n",
    "plt.figure(figsize=(16, 4 * n_rows))  # Adjust figure size based on the number of rows\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.barplot(x='LeadOutcome', y=feature, data=df)\n",
    "    plt.title(f'{feature} vs LeadOutcome')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_pXkbygDXPD"
   },
   "source": [
    "Insights:\n",
    "\n",
    "- Prompt Engagement: Leads with a shorter lag time for the first call and lower overall lead age have higher conversion rates, reinforcing the importance of reaching out to leads quickly.\n",
    "\n",
    "- Effective Call Management: Successful contacts and answered calls are more prevalent in converted leads. Focusing on call quality and ensuring successful contact is more impactful than merely increasing call attempts.\n",
    "\n",
    "- Marketing Permissions: Converted leads have a slightly higher rate of allowing marketing, which suggests that leads open to marketing communications might be more receptive to conversion efforts.\n",
    "\n",
    "Focusing on quick, successful initial engagement and optimizing call success rate can significantly improve lead conversion outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DedesgNHOCC"
   },
   "source": [
    "### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGDvxHmaHOCC",
    "outputId": "748e6fd3-2b9a-4570-d70b-e2cfe9a11ba5"
   },
   "outputs": [],
   "source": [
    "# Pairplot of a few important numerical features\n",
    "sns.pairplot(df, hue='LeadOutcome', diag_kind='kde', vars=numerical_features[:5])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtlSMi7jGQyD"
   },
   "source": [
    "Insight:\n",
    "\n",
    "- Marketing Permissions and Age are two features that may impact lead conversion, with younger individuals and those who allow marketing showing higher conversion tendencies.\n",
    "\n",
    "- AnnualMileage and NewPriceVatExcl do not appear to have strong influences on conversion outcomes.\n",
    "\n",
    "Focusing on target demographics that are younger and more open to marketing could improve lead conversion strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UPo4EjgHOCD"
   },
   "source": [
    "# <font color=black> 6. Model training</font> <a class=\"anchor\" id=\"chapter7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCv-1tVCHOCD"
   },
   "source": [
    "### Train-test split (80% training, 20% testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQ6HZZ2CHOCD"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhTlgXQmHOCD"
   },
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30tIBqDGHOCD",
    "outputId": "125dd314-1791-4095-9982-1772935a530f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "\n",
    "    # Fit the RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Log the model metrics to MLflow\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # save the model to MLflow\n",
    "    mlflow.sklearn.log_model(rf_model, \"random_forest_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "re57p--uHOCE"
   },
   "source": [
    "### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrhNccRQHOCE",
    "outputId": "b188627d-66a1-4675-b8d9-15799bf428de"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"Gradient Boosting\")\n",
    "\n",
    "    # Fit the Gradient Boosting model\n",
    "    gb_model = GradientBoostingClassifier(random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = gb_model.predict(X_test)\n",
    "\n",
    "    # Log the model metrics to MLflow\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_param(\"confusion_matrix\", conf_matrix)\n",
    "    mlflow.log_param(\"classification_report\", class_report)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # save the model to MLflow\n",
    "    mlflow.sklearn.log_model(gb_model, \"gradient_boosting_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likeyhood of convrsion based on  lead age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "\n",
    "# Select relevant features\n",
    "X = data[['Lead Age (Calendar Days)']]  # You can also include other age metrics\n",
    "y = data['LeadOutcome']  # Assuming this is binary (Converted / Not Converted)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Prepare data for Prophet (needs to be time-series format)\n",
    "df_prophet = data.groupby('LeadCreateDt')['LeadOutcome'].sum().reset_index()\n",
    "df_prophet.columns = ['ds', 'y']  # Prophet requires these column names\n",
    "\n",
    "# Fit Prophet model\n",
    "model = Prophet()\n",
    "model.fit(df_prophet)\n",
    "\n",
    "# Predict future lead conversions\n",
    "future = model.make_future_dataframe(periods=365)  # Predict for the next 365 days\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Plot results\n",
    "model.plot(forecast)\n",
    "plt.title('Lead Conversions with Seasonality')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Tevin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
